{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam          \n",
    "from tensorflow.keras.applications import MobileNetV2 \n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION DES PARAMÈTRES\n",
    "DATA_DIR = r\"data/\"\n",
    "\n",
    "if DATA_DIR == \"data\":\n",
    "    raise ValueError(\"Veuillez modifier la variable 'DATA_DIR' pour pointer vers votre dossier de données.\")\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"Le dossier spécifié n'existe pas : {DATA_DIR}\")\n",
    "\n",
    "# Paramètres du modèle\n",
    "IMG_HEIGHT = 224 \n",
    "IMG_WIDTH = 224   \n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50     \n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 0.0001 \n",
    "\n",
    "print(\" 2. CHARGEMENT ET PRÉTRAITEMENT DES DONNÉES \")\n",
    "\n",
    "# Chargement des données d'entraînement\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Chargement des données de validation\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Récupérer les noms des classes\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes trouvées : {class_names} (Total: {num_classes})\")\n",
    "\n",
    "\n",
    "# DATA AUGMENTATION (ET NORMALISATION) \n",
    "print(\"\\n 3. DATA AUGMENTATION (RENFORCÉE) \")\n",
    "\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomBrightness(0.2),  \n",
    "        layers.RandomContrast(0.2)     \n",
    "    ],\n",
    "    name=\"data_augmentation\"\n",
    ")\n",
    "\n",
    "# Optimiser les performances\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"\\n 4. CONSTRUCTION DU MODÈLE (TRANSFER LEARNING) \")\n",
    "\n",
    "# Charger le modèle de base (MobileNetV2) pré-entraîné sur ImageNet\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Geler le modèle de base\n",
    "base_model.trainable = False\n",
    "\n",
    "# Créer notre nouveau modèle\n",
    "model = Sequential([\n",
    "    # Couche d'augmentation\n",
    "    data_augmentation,\n",
    "\n",
    "    # Couche de normalisation (IMPORTANT)\n",
    "    # MobileNetV2 attend des pixels entre [-1, 1], pas [0, 255] ou [0, 1]\n",
    "    layers.Rescaling(1./127.5, offset=-1),\n",
    "\n",
    "    # Le modèle de base (gelé)\n",
    "    base_model,\n",
    "\n",
    "    # Nos propres couches de classification\n",
    "    GlobalAveragePooling2D(), # Transforme la sortie en vecteur 1D (mieux que Flatten)\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "], name=\"Fruit_Classifier_TransferLearning\")\n",
    "\n",
    "\n",
    "# COMPILATION DU MODÈLE \n",
    "print(\"\\n 5. COMPILATION DU MODÈLE \")\n",
    "\n",
    "# Utiliser un optimiseur Adam avec un taux d'apprentissage plus faible\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Afficher un résumé de l'architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# ENTRAÎNEMENT DU MODÈLE \n",
    "print(\"\\n 6. ENTRAÎNEMENT DU MODÈLE \")\n",
    "\n",
    "# Définir le callback EarlyStopping\n",
    "# Il arrêtera l'entraînement si la 'val_loss' ne s'améliore pas\n",
    "# pendant 'patience' époques.\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     \n",
    "    patience=5,             \n",
    "    verbose=1,\n",
    "    restore_best_weights=True \n",
    ") \n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping] \n",
    ")\n",
    "\n",
    "\n",
    "# ÉVALUATION ET VISUALISATION DES RÉSULTATS \n",
    "print(\"\\n 7. ÉVALUATION ET VISUALISATION DES RÉSULTATS \")\n",
    "\n",
    "# Graphiques d'Accuracy et de Perte \n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Utiliser le nombre d'époques *réellement* exécutées\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Accuracy (Entraînement)\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Accuracy (Validation)\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Accuracy (Entraînement et Validation)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Perte (Entraînement)\")\n",
    "plt.plot(epochs_range, val_loss, label=\"Perte (Validation)\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Perte (Entraînement et Validation)\")\n",
    "plt.suptitle(f\"Métriques d'entraînement (Meilleure époque: {np.argmin(val_loss)})\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Matrice de Confusion\n",
    "print(\"\\nCalcul de la matrice de confusion...\")\n",
    "\n",
    "# Prédire sur l'ensemble de validation complet\n",
    "y_pred_probs = model.predict(val_dataset)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Obtenir les vraies étiquettes\n",
    "y_true = np.concatenate([y for x, y in val_dataset], axis=0)\n",
    "\n",
    "# Calculer la matrice\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Afficher la matrice avec Seaborn\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sn.heatmap(df_cm, annot=True, fmt='g', cmap='Blues')\n",
    "plt.title(f'Matrice de Confusion\\nAccuracy: {np.trace(cm) / np.sum(cm):.2%}')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies étiquettes')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nScript terminé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21f7673f36920794a23d967940019a3216ee600a9830756ae9ea43be8d2e35af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
